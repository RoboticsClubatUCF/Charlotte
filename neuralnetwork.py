# -*- coding: utf-8 -*-
"""NeuralNetwork.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/102er2xCF6NHe4CIdbIa-B69GWroa3RiR
"""

from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50, decode_predictions
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.layers import Input
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np

# Creates an input tensor with the shape 
#new_input_tensor = Input(shape=(28, 28, 1))

# Creates the base model while removing the top layer
base_model = ResNet50(weights='imagenet', include_top= False)

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation="relu")(x)
predictions = Dense(5, activation="softmax")(x)

real_model = Model(inputs=base_model.input, outputs=predictions)

for layer in real_model.layers:
  layer.trainable = False

# Compiles and trains the data using the rmsprop optimizer
real_model.compile(optimizer="rmsprop", loss="categorical_crossentropy")

# Load Data using Keras

batch_size = 16
img_height = 224
img_width = 224

train_ds = tf.keras.utils.image_dataset_from_directory (
    directory = "Data",
    validation_split = 0.2,
    subset = "training", 
    seed = 123,
    image_size = (img_height, img_width), 
    batch_size=batch_size
)

val_ds = tf.keras.utils.image_dataset_from_directory (
  directory = "Data",
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size
)

class_names = train_ds.class_names
print(class_names)

plt.figure(figsize=(10, 10))
  
  for images, labels in train_ds.take(1):
    for i in range(9):
      ax = plt.subplot(3, 3, i + 1)
      plt.imshow(images[i].numpy().astype("uint8"))
      plt.title(class_names[labels[i]])
      plt.axis("off")

# Loads and Preprocesses Images
def preprocess(img, x):
  return preprocess_input(float(img))

new_train = train_ds.map(preprocess)
new_val = val_ds.map(preprocess)

# Shuffles the test data and trains the data for a certain amount of epochs

history = real_model.fit(new_train, validation_data = new_val, epochs = 5)

img = image.load_img("Flower.jpg", target_size=(224, 224))
mod = image.img_to_array(img)
mod = np.expand_dims(mod, axis = 0)
mod = preprocess_input(mod)

preds = real_model.predict(mod)
print(len(preds[0]))
print("I think its ", preds)